{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM VAE.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "dtKtB8cqVMwY"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SalmanMohammadi/computing_science_diss/blob/master/LSTM_VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "_wqDUqzuvPmF",
        "colab_type": "code",
        "outputId": "efab7c08-3e02-4bb5-cc9e-c98bcc6aa5b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "cell_type": "code",
      "source": [
        "# Hack to allow python to pick up the newly-installed fluidsynth lib.\n",
        "# import ctypes.util\n",
        "# def proxy_find_library(lib):\n",
        "#   if lib == 'fluidsynth':\n",
        "#     return 'libfluidsynth.so.1'\n",
        "#   else:\n",
        "#     return ctypes.util.find_library(lib)\n",
        "\n",
        "# ctypes.util.find_library = proxy_find_library\n",
        "\n",
        "# Download Salamander piano SoundFont.\n",
        "# Samples by Alexander Holm: https://archive.org/details/SalamanderGrandPianoV3\n",
        "# Converted to sf2 by John Nebauer: https://sites.google.com/site/soundfonts4u\n",
        "!gsutil -m cp gs://download.magenta.tensorflow.org/soundfonts/Yamaha-C5-Salamander-JNv5.1.sf2 /tmp/\n",
        "\n",
        "# Setting up Tensorboard\n",
        "\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://download.magenta.tensorflow.org/soundfonts/Yamaha-C5-Salamander-JNv5.1.sf2...\n",
            "- [1/1 files][591.9 MiB/591.9 MiB] 100% Done  48.3 MiB/s ETA 00:00:00           \n",
            "Operation completed over 1 objects/591.9 MiB.                                    \n",
            "--2019-01-16 11:20:15--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.203.66.95, 52.22.145.207, 52.203.53.176, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.203.66.95|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5363700 (5.1M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]   5.11M  3.47MB/s    in 1.5s    \n",
            "\n",
            "2019-01-16 11:20:18 (3.47 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [5363700/5363700]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lec5b6nK1Tu3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "!rm -rf /content/log/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R6oWoXv3vR19",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -q magenta\\\n",
        "                music21"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SnK9bwx2tRvt",
        "colab_type": "code",
        "outputId": "418bdeb5-435d-4c08-ec5d-da1e1eced3d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1218
        }
      },
      "cell_type": "code",
      "source": [
        "# from __future__ import absolute_import\n",
        "import magenta as mg\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "# from music21 import converter, instrument, note, chord\n",
        "# import numpy as np\n",
        "# import tensorflow.keras as keras"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/scipy/signal/_max_len_seq.py:8: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from ._max_len_seq_inner import _max_len_seq_inner\n",
            "/usr/local/lib/python2.7/dist-packages/scipy/signal/_upfirdn.py:36: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from ._upfirdn_apply import _output_len, _apply\n",
            "/usr/local/lib/python2.7/dist-packages/scipy/signal/spectral.py:10: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from ._spectral import _lombscargle\n",
            "/usr/local/lib/python2.7/dist-packages/scipy/signal/_peak_finding.py:13: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from ._peak_finding_utils import (_argmaxima1d, _select_by_peak_distance,\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/base.py:35: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from ..utils.seq_dataset import ArrayDataset, CSRDataset\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/least_angle.py:23: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from ..utils import arrayfuncs, as_float_array, check_X_y, deprecated\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/utils/random.py:10: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from ._random import sample_without_replacement\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/coordinate_descent.py:30: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from . import cd_fast\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/__init__.py:22: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from .sgd_fast import Hinge, Log, ModifiedHuber, SquaredLoss, Huber\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/__init__.py:22: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from .sgd_fast import Hinge, Log, ModifiedHuber, SquaredLoss, Huber\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/sag.py:12: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from .sag_fast import sag\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/svm/base.py:8: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from . import libsvm, liblinear\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/svm/base.py:8: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from . import libsvm, liblinear\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/svm/base.py:9: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from . import libsvm_sparse\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/neighbors/__init__.py:6: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from .ball_tree import BallTree\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/neighbors/__init__.py:6: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from .ball_tree import BallTree\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/neighbors/__init__.py:6: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from .ball_tree import BallTree\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/neighbors/__init__.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from .kd_tree import KDTree\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/decomposition/online_lda.py:28: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from ._online_lda import (mean_change, _dirichlet_expectation_1d,\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/utils/graph.py:16: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from .graph_shortest_path import graph_shortest_path  # noqa\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/isotonic.py:11: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from ._isotonic import _inplace_contiguous_isotonic_regression, _make_unique\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/manifold/t_sne.py:26: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from . import _utils\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/manifold/t_sne.py:27: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from . import _barnes_hut_tsne\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/manifold/t_sne.py:27: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from . import _barnes_hut_tsne\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/tree/tree.py:40: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from ._criterion import Criterion\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/tree/tree.py:40: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from ._criterion import Criterion\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/tree/tree.py:40: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from ._criterion import Criterion\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/tree/tree.py:40: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from ._criterion import Criterion\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/cluster/k_means_.py:37: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from . import _k_means\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/cluster/k_means_.py:38: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from ._k_means_elkan import k_means_elkan\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/cluster/hierarchical.py:23: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from . import _hierarchical\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/cluster/hierarchical.py:23: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from . import _hierarchical\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/cluster/dbscan_.py:20: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from ._dbscan_inner import dbscan_inner\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/feature_extraction/hashing.py:14: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from ._hashing import transform as _hashing_transform\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "ysFVhp74vT-v",
        "colab_type": "code",
        "outputId": "d3bf6257-f9ec-4ad4-ef0b-501b520f14b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "LOG_DIR = '/content/log'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://2a14fdff.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BRvYdzpAN7CF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp -r /content/log/run0/ /saved"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pCY322lE6tZy",
        "colab_type": "code",
        "outputId": "4dd38c4b-a115-46a0-afc9-dae175d12b72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!ls /content/log/run0/train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ls: cannot access '/content/log/run0/train': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "N4QDVcQ7vYTd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data"
      ]
    },
    {
      "metadata": {
        "id": "ObBd9_XnVIEd",
        "colab_type": "code",
        "outputId": "f220e078-33cb-4a28-84f2-ba26396662c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "cell_type": "code",
      "source": [
        "# Grab some data\n",
        "# !git clone https://github.com/Skuldur/Classical-Piano-Composer\n",
        "# !git clone https://github.com/brannondorsey/midi-rnn\n",
        "# !wget https://storage.googleapis.com/magentadata/datasets/maestro/v1.0.0/maestro-v1.0.0-midi.zip\n",
        "# !wget \"www.kuhmann.com/Disklavier/Classical-II%20(215)%20MID.zip\"\n",
        "# !wget \"www.kuhmann.com/Disklavier/Classical-I%20(001-215)%20MID.zip\"\n",
        "!wget https://storage.googleapis.com/maestro-performance/training_performances.tfrecord\n",
        "\n",
        "# Organise MIDI files for parsing\n",
        "# !mkdir data\n",
        "# !unzip 'Classical-I (001-215) MID.zip' -q -d /content/data/\n",
        "# !unzip 'Classical-II (215) MID.zip' -d /content/data/\n",
        "# !unzip 'maestro-v1.0.0-midi.zip' -d  data\n",
        "# !mv Classical-Piano-Composer/midi_songs/*.mid /content/data/\n",
        "!mkdir sequences\n",
        "!mv training_performances.tfrecord sequences/\n",
        "!ls data"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-01-16 11:21:21--  https://storage.googleapis.com/maestro-performance/training_performances.tfrecord\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.97.128, 2404:6800:4008:c00::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.97.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 31145373696 (29G) [application/octet-stream]\n",
            "Saving to: ‘training_performances.tfrecord’\n",
            "\n",
            "training_performanc 100%[===================>]  29.01G  40.0MB/s    in 18m 56s \n",
            "\n",
            "2019-01-16 11:40:18 (26.1 MB/s) - ‘training_performances.tfrecord’ saved [31145373696/31145373696]\n",
            "\n",
            "ls: cannot access 'data': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wOpR2sYHSONb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Parse our MIDI files using magenta\n",
        "!python /usr/local/lib/python2.7/dist-packages/magenta/scripts/convert_dir_to_note_sequences.py \\\n",
        "        --input_dir='data/maestro-v1.0.0' \\\n",
        "        --output_file='tfrecords/notesequences.tfrecord'\\\n",
        "        --recursive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8tnbhvb9bc52",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Augment and slice data for input into our model\n",
        "!python /usr/local/lib/python2.7/dist-packages/magenta/models/performance_rnn/performance_rnn_create_dataset.py \\\n",
        "        --config=performance_with_dynamics \\\n",
        "        --eval_ratio=0.2 \\\n",
        "        --input=tfrecords/notesequences.tfrecord \\\n",
        "        --output_dir=sequences "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TxmZC7Dd2uiU",
        "colab_type": "code",
        "outputId": "f03b84dc-09fd-4b03-baab-0c1ad057d124",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "!ls -lh /content/tfrecords"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 25M\n",
            "-rw-r--r-- 1 root root 25M Jan  7 13:30 notesequences.tfrecord\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6vcwkZKHN6ge",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Utils"
      ]
    },
    {
      "metadata": {
        "id": "Cak02khJN-jQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_deep_lstm(layers, dropouts):\n",
        "  cells = [tf.nn.rnn_cell.LSTMCell(size, reuse=tf.AUTO_REUSE) for size in layers]\n",
        "  cells = [tf.contrib.rnn.DropoutWrapper(cell, prob) for prob, cell in zip(dropouts, cells)]\n",
        "  return tf.contrib.rnn.MultiRNNCell(cells)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wyM5y26Wa16j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## LSTM"
      ]
    },
    {
      "metadata": {
        "id": "pTucAMe-br-u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.python.util import nest as tf_nest\n",
        "\n",
        "def build_lstm(config, mode):\n",
        "  \n",
        "  def build_graph():\n",
        "\n",
        "    encoder_decoder = config['encoder_decoder']\n",
        "    input_size = encoder_decoder.input_size\n",
        "    num_classes = encoder_decoder.num_classes\n",
        "    default_event_label = encoder_decoder.default_event_label\n",
        "\n",
        "    batch_size = 64\n",
        "    label_shape = []\n",
        "    learning_rate = config['learning_rate']\n",
        "    inputs, labels, lengths = None, None, None\n",
        "    if mode == 'train' or mode == 'eval':\n",
        "      inputs, labels, lengths = mg.common.get_padded_batch(\n",
        "                ['/content/sequences/training_performances.tfrecord'], batch_size, input_size,\n",
        "                label_shape=label_shape, shuffle=mode == 'train')\n",
        "    else:\n",
        "      inputs = tf.placeholder(tf.float32, [batch_size, None,\n",
        "                                           input_size]) \n",
        "    config['dropouts'] = [1.0 if mode == 'generate' else dropout for dropout in config['dropouts']]\n",
        "    cell = get_deep_lstm(config['rnn_layers'], config['dropouts'])\n",
        "    initial_state = cell.zero_state(batch_size, tf.float32)\n",
        "    outputs, final_state = tf.nn.dynamic_rnn(\n",
        "        cell, inputs, sequence_length=lengths, initial_state=initial_state,\n",
        "        swap_memory=True)\n",
        "\n",
        "    outputs_flat = mg.common.flatten_maybe_padded_sequences(\n",
        "            outputs, lengths)\n",
        "\n",
        "    num_logits = num_classes\n",
        "    logits_flat = tf.contrib.layers.linear(outputs_flat, num_logits)\n",
        "    print(mode)\n",
        "    if mode == 'train' or mode == 'eval':\n",
        "      labels_flat = mg.common.flatten_maybe_padded_sequences(\n",
        "              labels, lengths)\n",
        "      softmax_cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "            labels=labels_flat, logits=logits_flat)\n",
        "      predictions_flat = tf.argmax(logits_flat, axis=1)\n",
        "      correct_predictions = tf.to_float(\n",
        "          tf.equal(labels_flat, predictions_flat))\n",
        "      event_positions = tf.to_float(tf.not_equal(labels_flat, default_event_label))\n",
        "      no_event_positions = tf.to_float(tf.equal(labels_flat, default_event_label))\n",
        "\n",
        "      loss = tf.reduce_mean(softmax_cross_entropy)\n",
        "      optimizer = config['optimizer'](learning_rate=config['learning_rate'])\n",
        "      train_op = tf.contrib.slim.learning.create_train_op(loss, optimizer)\n",
        "      \n",
        "      tf.summary.scalar('loss', loss)\n",
        "      tf.add_to_collection('loss', loss)\n",
        "      tf.add_to_collection('train_op', train_op)\n",
        "      tf.add_to_collection('optimizer', optimizer)\n",
        "    elif mode == 'generate':\n",
        "      temperature = tf.placeholder(tf.float32, [])\n",
        "      softmax_flat = tf.nn.softmax(\n",
        "            tf.div(logits_flat, tf.fill([num_classes], temperature)))\n",
        "      softmax = tf.reshape(\n",
        "            softmax_flat, [batch_size, -1, num_classes])\n",
        "    \n",
        "      tf.add_to_collection('inputs', inputs)\n",
        "      tf.add_to_collection('temperature', temperature)\n",
        "      tf.add_to_collection('softmax', softmax)\n",
        "\n",
        "      for state in tf_nest.flatten(initial_state):\n",
        "        tf.add_to_collection('initial_state', state)\n",
        "      for state in tf_nest.flatten(final_state):\n",
        "        tf.add_to_collection('final_state', state)\n",
        "  return build_graph"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "73m11eHqWim7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "run_no = 0\n",
        "runs_info = {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TrEsl0WhT8ex",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "runs_info[run_no] = {\n",
        "    'rnn_layers': [512, 512],\n",
        "    'dropouts': [0.70, 0.70],\n",
        "    'optimizer': tf.train.RMSPropOptimizer,\n",
        "    'learning_rate': 0.01,\n",
        "    'encoder_decoder': mg.music.OneHotEventSequenceEncoderDecoder(\n",
        "            mg.music.PerformanceOneHotEncoding(\n",
        "                num_velocity_bins=32)),\n",
        "    'steps': 4000\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t1bUduAf19yf",
        "colab_type": "code",
        "outputId": "0846053f-64be-4c58-e0bf-b04869031874",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.Graph().as_default():\n",
        "  build_lstm(runs_info[run_no], 'train')()\n",
        "  \n",
        "  global_step = tf.train.get_or_create_global_step()\n",
        "  loss = tf.get_collection('loss')[0]\n",
        "  optimizer = tf.get_collection('optimizer')[0].minimize(loss)\n",
        "  train_op = tf.get_collection('train_op')[0]\n",
        "  logging_dict = {\n",
        "      'global_step': global_step,\n",
        "      'loss': loss\n",
        "  }\n",
        "  hooks = [\n",
        "      tf.train.NanTensorHook(loss),\n",
        "      tf.train.LoggingTensorHook(\n",
        "          logging_dict, every_n_iter=100),\n",
        "      tf.train.StopAtStepHook(runs_info[run_no]['steps'])\n",
        "  ]\n",
        "  \n",
        "  tf.logging.info('Starting training loop...')\n",
        "  tf.contrib.training.train(train_op=train_op, \n",
        "                            logdir='/content/log/run' + str(run_no),\n",
        "                            hooks=hooks,\n",
        "                            save_checkpoint_secs=1200,\n",
        "                            save_summaries_steps=100)\n",
        "  tf.logging.info('Training loop complete.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/magenta/common/sequence_example_lib.py:92: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.py:276: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.py:188: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.py:197: __init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/input.py:197: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/magenta/common/sequence_example_lib.py:93: __init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TFRecordDataset`.\n",
            "INFO:tensorflow:Counting records in /content/sequences/training_performances.tfrecord.\n",
            "INFO:tensorflow:Number of records is at least 100.\n",
            "INFO:tensorflow:[<tf.Tensor 'random_shuffle_queue_Dequeue:0' shape=(?, 388) dtype=float32>, <tf.Tensor 'random_shuffle_queue_Dequeue:1' shape=(?,) dtype=int64>, <tf.Tensor 'random_shuffle_queue_Dequeue:2' shape=() dtype=int32>]\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/magenta/common/sequence_example_lib.py:132: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n",
            "train\n",
            "INFO:tensorflow:Starting training loop...\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "WARNING:tensorflow:Issue encountered when serializing optimizer.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "'RMSPropOptimizer' object has no attribute 'name'\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:Issue encountered when serializing optimizer.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "'RMSPropOptimizer' object has no attribute 'name'\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /content/log/run0/model.ckpt.\n",
            "WARNING:tensorflow:Issue encountered when serializing optimizer.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "'RMSPropOptimizer' object has no attribute 'name'\n",
            "INFO:tensorflow:global_step = 0, loss = 5.9602985\n",
            "INFO:tensorflow:global_step/sec: 0.553332\n",
            "INFO:tensorflow:global_step = 100, loss = 4.8571167 (180.730 sec)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "z6EwaJL63sCK",
        "colab_type": "code",
        "outputId": "1c8630d9-1619-4f8b-8794-9447ffa04209",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        }
      },
      "cell_type": "code",
      "source": [
        "run_no += 1\n",
        "run_no\n",
        "runs_info"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: {'dropouts': [0.2, 0.2],\n",
              "  'encoder_decoder': <magenta.music.encoder_decoder.OneHotEventSequenceEncoderDecoder at 0x7f06741ede10>,\n",
              "  'learning_rate': 0.01,\n",
              "  'optimizer': tensorflow.python.training.adam.AdamOptimizer,\n",
              "  'rnn_layers': [512, 512],\n",
              "  'steps': 4000},\n",
              " 1: {'dropouts': [0.2, 0.2],\n",
              "  'encoder_decoder': <magenta.music.encoder_decoder.OneHotEventSequenceEncoderDecoder at 0x7f0674d08350>,\n",
              "  'learning_rate': 0.01,\n",
              "  'optimizer': tensorflow.python.training.adam.AdamOptimizer,\n",
              "  'rnn_layers': [512, 512],\n",
              "  'steps': 4000},\n",
              " 2: {'dropouts': [0.2, 0.2],\n",
              "  'encoder_decoder': <magenta.music.encoder_decoder.OneHotEventSequenceEncoderDecoder at 0x7f06739e2690>,\n",
              "  'learning_rate': 0.001,\n",
              "  'optimizer': tensorflow.python.training.adadelta.AdadeltaOptimizer,\n",
              "  'rnn_layers': [512, 512],\n",
              "  'steps': 4000},\n",
              " 3: {'dropouts': [0.35, 0.35],\n",
              "  'encoder_decoder': <magenta.music.encoder_decoder.OneHotEventSequenceEncoderDecoder at 0x7f0672010510>,\n",
              "  'learning_rate': 0.009,\n",
              "  'optimizer': tensorflow.python.training.rmsprop.RMSPropOptimizer,\n",
              "  'rnn_layers': [512, 512],\n",
              "  'steps': 4000},\n",
              " 4: {'dropouts': [0.7, 0.7],\n",
              "  'encoder_decoder': <magenta.music.encoder_decoder.OneHotEventSequenceEncoderDecoder at 0x7f06742f4150>,\n",
              "  'learning_rate': 0.01,\n",
              "  'optimizer': tensorflow.python.training.rmsprop.RMSPropOptimizer,\n",
              "  'rnn_layers': [512, 512],\n",
              "  'steps': 4000}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "metadata": {
        "id": "_F5bIIGAr5ss",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Generate, baby"
      ]
    },
    {
      "metadata": {
        "id": "SXy3WZ_hoFO0",
        "colab_type": "code",
        "outputId": "2cd83155-de47-4295-a06e-1b1a01810b4b",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 171
        }
      },
      "cell_type": "code",
      "source": [
        "# Upload a model\n",
        "from google.colab import files\n",
        "# files.upload()\n",
        "files.upload()\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a1f78d32-92c6-48f5-a90a-2a9128b50525\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-a1f78d32-92c6-48f5-a90a-2a9128b50525\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving model.ckpt-1931.meta to model.ckpt-1931.meta\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-04a142e0-2c66-48df-8eb4-5e1ca4d0f0d1\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-04a142e0-2c66-48df-8eb4-5e1ca4d0f0d1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving model.ckpt-1931.index to model.ckpt-1931.index\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{u'model.ckpt-1931.index': '\\x00\\x00\\x06\\x08\\x01\\x1a\\x02\\x08\\x01\\x00\\x16\\x11fully_connected/biases\\x08\\x01\\x12\\x05\\x12\\x03\\x08\\x84\\x03(\\x90\\x0c5\\xd3\\x08\\x8cc\\x16\\x08\\x14/RMSProp\\x08\\x01\\x12\\x05\\x12\\x03\\x08\\x84\\x03 \\x90\\x0c(\\x90\\x0c5\\x01\\x86\\xa9\\xa9\\x1e\\x02\\x14_1\\x08\\x01\\x12\\x05\\x12\\x03\\x08\\x84\\x03 \\xa0\\x18(\\x90\\x0c54\\xa03\\x19\\x10\\x07\\x1aweights\\x08\\x01\\x12\\n\\x12\\x03\\x08\\x80\\x04\\x12\\x03\\x08\\x84\\x03 \\xb0$(\\x80\\xc005Z\\x0c\\xac\\x10\\x17\\x08\\x1b/RMSProp\\x08\\x01\\x12\\n\\x12\\x03\\x08\\x80\\x04\\x12\\x03\\x08\\x84\\x03 \\xb0\\xe40(\\x80\\xc005\\xa1\\xfd\\xa5K\\x1f\\x02\\x1b_1\\x08\\x01\\x12\\n\\x12\\x03\\x08\\x80\\x04\\x12\\x03\\x08\\x84\\x03 \\xb0\\xa4a(\\x80\\xc005\\xfbH=W\\x00\\x0b\\x10global_step\\x08\\t\\x12\\x00 \\xb0\\xe4\\x91\\x01(\\x085>d+\\xd2\\x00(\\x16rnn/multi_rnn_cell/cell_0/lstm_cell/bias\\x08\\x01\\x12\\x05\\x12\\x03\\x08\\x80\\x10 \\xb8\\xe4\\x91\\x01(\\x80@5\\xcae\\x8d\\x9d(\\x08\\x16/RMSProp\\x08\\x01\\x12\\x05\\x12\\x03\\x08\\x80\\x10 \\xb8\\xa4\\x92\\x01(\\x80@5TH\\xce\\x8f0\\x02\\x16_1\\x08\\x01\\x12\\x05\\x12\\x03\\x08\\x80\\x10 \\xb8\\xe4\\x92\\x01(\\x80@5T\\xd8E\\x06$\\x06\\x1dkernel\\x08\\x01\\x12\\n\\x12\\x03\\x08\\x84\\x07\\x12\\x03\\x08\\x80\\x10 \\xb8\\xa4\\x93\\x01(\\x80\\x80\\xc2\\x035\\xbd\\x1ef\\x8f*\\x08\\x1d/RMSProp\\x08\\x01\\x12\\n\\x12\\x03\\x08\\x84\\x07\\x12\\x03\\x08\\x80\\x10 \\xb8\\xa4\\xd5\\x04(\\x80\\x80\\xc2\\x035`\\x1a\\x11\\xb12\\x02\\x1d_1\\x08\\x01\\x12\\n\\x12\\x03\\x08\\x84\\x07\\x12\\x03\\x08\\x80\\x10 \\xb8\\xa4\\x97\\x08(\\x80\\x80\\xc2\\x035\\xf1\\xf9\\xc9\\xf7\\x18\\x10\\x161/lstm_cell/bias\\x08\\x01\\x12\\x05\\x12\\x03\\x08\\x80\\x10 \\xb8\\xa4\\xd9\\x0b(\\x80@5q\\x1e\\xbf#(\\x08\\x16/RMSProp\\x08\\x01\\x12\\x05\\x12\\x03\\x08\\x80\\x10 \\xb8\\xe4\\xd9\\x0b(\\x80@5\\xb0gX6\\x002\\x16rnn/multi_rnn_cell/cell_1/lstm_cell/bias/RMSProp_1\\x08\\x01\\x12\\x05\\x12\\x03\\x08\\x80\\x10 \\xb8\\xa4\\xda\\x0b(\\x80@5I\\xfd\\xefx$\\x06\\x1dkernel\\x08\\x01\\x12\\n\\x12\\x03\\x08\\x80\\x08\\x12\\x03\\x08\\x80\\x10 \\xb8\\xe4\\xda\\x0b(\\x80\\x80\\x80\\x045U\\xe1\\n!*\\x08\\x1d/RMSProp\\x08\\x01\\x12\\n\\x12\\x03\\x08\\x80\\x08\\x12\\x03\\x08\\x80\\x10 \\xb8\\xe4\\xda\\x0f(\\x80\\x80\\x80\\x045\\xfe\\x043\\xe92\\x02\\x1d_1\\x08\\x01\\x12\\n\\x12\\x03\\x08\\x80\\x08\\x12\\x03\\x08\\x80\\x10 \\xb8\\xe4\\xda\\x13(\\x80\\x80\\x80\\x045\\xc2\\x9e\\x06;\\x00\\x00\\x00\\x00*\\x02\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\xb3\\xc6gs\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\xc0\\xf2\\xa1\\xb0\\x00\\x01\\x03s\\x00\\xf1\\x05\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x00\\xd2T\\x1cO\\xf6\\x05\\x08\\x83\\x06\\x0f\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00W\\xfb\\x80\\x8b$uG\\xdb'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "7LjpqUl3EGnn",
        "colab_type": "code",
        "outputId": "638a2ed4-951a-4012-bf18-8974e09b4677",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "cell_type": "code",
      "source": [
        "!ls /content/log/run0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\n",
            "events.out.tfevents.1546873916.6a2b1eed8d88\n",
            "graph.pbtxt\n",
            "model.ckpt-0.data-00000-of-00001\n",
            "model.ckpt-0.index\n",
            "model.ckpt-0.meta\n",
            "model.ckpt-1931.data-00000-of-00001\n",
            "model.ckpt-1931.index\n",
            "model.ckpt-1931.meta\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TVyhxGTPCDbT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir /content/log/run0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i0HU-srwE1oQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp  /content/model.ckpt-1931.index /content/log/run0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wlAWbmq3EA0U",
        "colab_type": "code",
        "outputId": "5bbf5fc4-3df7-440f-e08c-e2b2eef94e81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        }
      },
      "cell_type": "code",
      "source": [
        "# Download files\n",
        "from google.colab import files\n",
        "number = 1931\n",
        "run_no = 0\n",
        "run_dir = '/content/log/run' + str(run_no) + '/'\n",
        "files.download(run_dir + 'model.ckpt-' + str(number) + '.data-00000-of-00001')\n",
        "files.download(run_dir + 'model.ckpt-' + str(number) + '.index')\n",
        "files.download(run_dir + 'model.ckpt-' + str(number) + '.meta')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-4d2698d0ccee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrun_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/log/run'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_no\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'model.ckpt-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.data-00000-of-00001'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'model.ckpt-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'model.ckpt-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.meta'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/google/colab/files.pyc\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0;34m'port'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m       \u001b[0;34m'path'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m       \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m   })\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/google/colab/output/_js.pyc\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/google/colab/_message.pyc\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "wQ8TunMBX8UC",
        "colab_type": "code",
        "outputId": "3f1ca726-2e5c-417b-def0-379432845a7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "cell_type": "code",
      "source": [
        "runs_info"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: {'dropouts': [1.0, 1.0, 1.0],\n",
              "  'encoder_decoder': <magenta.music.encoder_decoder.OneHotEventSequenceEncoderDecoder at 0x7f3978f558d0>,\n",
              "  'learning_rate': 0.001,\n",
              "  'optimizer': tensorflow.python.training.gradient_descent.GradientDescentOptimizer,\n",
              "  'rnn_layers': [512, 512, 512]},\n",
              " 1: {'dropouts': [1.0, 1.0],\n",
              "  'encoder_decoder': <magenta.music.encoder_decoder.OneHotEventSequenceEncoderDecoder at 0x7f39770f1b90>,\n",
              "  'learning_rate': 0.001,\n",
              "  'optimizer': tensorflow.python.training.gradient_descent.GradientDescentOptimizer,\n",
              "  'rnn_layers': [512, 512]},\n",
              " 2: {'dropouts': [0.2, 0.2],\n",
              "  'encoder_decoder': <magenta.music.encoder_decoder.OneHotEventSequenceEncoderDecoder at 0x7f397761e050>,\n",
              "  'learning_rate': 0.001,\n",
              "  'optimizer': tensorflow.python.training.adam.AdamOptimizer,\n",
              "  'rnn_layers': [512, 512]},\n",
              " 3: {'dropouts': [0.2, 0.2],\n",
              "  'encoder_decoder': <magenta.music.encoder_decoder.OneHotEventSequenceEncoderDecoder at 0x7f39774ca310>,\n",
              "  'learning_rate': 0.01,\n",
              "  'optimizer': tensorflow.python.training.rmsprop.RMSPropOptimizer,\n",
              "  'rnn_layers': [512, 512]}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "metadata": {
        "id": "AEJqcLDWsA4l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from magenta.protobuf import generator_pb2\n",
        "from magenta.common import state_util\n",
        "import tempfile\n",
        "# Specify a trained model to use\n",
        "\n",
        "def generate(checkpoint_dir, number, run_no):\n",
        "  # Initialize the graph\n",
        "  bundle_file = checkpoint_dir + 'bundle.mag'\n",
        "  checkpoint_filename = os.path.join(checkpoint_dir, 'model.ckpt-' + str(number))\n",
        "  metagraph_filename = os.path.join(checkpoint_dir, 'model.ckpt-' + str(number) + '.meta')\n",
        "  print(checkpoint_filename)\n",
        "  with tf.Graph().as_default() as g:\n",
        "    \n",
        "    # just checkpoint\n",
        "    build_lstm(runs_info[run_no], 'generate')()\n",
        "    sess = tf.Session(graph=g)\n",
        "    saver = tf.train.Saver()\n",
        "    tf.logging.info('Checkpoint used: %s', checkpoint_filename)\n",
        "    saver.restore(sess, checkpoint_filename)\n",
        "     \n",
        "    try:\n",
        "      tempdir = tempfile.mkdtemp()\n",
        "      checkpoint_filename = os.path.join(tempdir, 'model.ckpt')\n",
        "      saver = tf.train.Saver(sharded=False, write_version=tf.train.SaverDef.V1)\n",
        "      saver.save(sess, checkpoint_filename, meta_graph_suffix='meta',\n",
        "                 write_meta_graph=True)\n",
        "      metagraph_filename = checkpoint_filename + '.meta'\n",
        "      bundle = generator_pb2.GeneratorBundle()\n",
        "      \n",
        "      details = generator_pb2.GeneratorDetails(\n",
        "                id='performance_with_dynamics',\n",
        "                description='Performance RNN with dynamics (compact input)')\n",
        "      bundle.generator_details.CopyFrom(details)\n",
        "\n",
        "      with tf.gfile.Open(checkpoint_filename, 'rb') as f:\n",
        "        bundle.checkpoint_file.append(f.read())\n",
        "      with tf.gfile.Open(metagraph_filename, 'rb') as f:\n",
        "        bundle.metagraph_file = f.read()\n",
        "\n",
        "      with tf.gfile.Open(bundle_file, 'wb') as f:\n",
        "        f.write(bundle.SerializeToString())   \n",
        "\n",
        "    finally:\n",
        "      if tempdir is not None:\n",
        "        tf.gfile.DeleteRecursively(tempdir)\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8N-NLFwMqSiw",
        "colab_type": "code",
        "outputId": "e6dc1f98-6d0c-4075-ab54-ae3f1dea733a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "cell_type": "code",
      "source": [
        "generate('/content/log/run0', 1931, 0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/log/run0/model.ckpt-1931\n",
            "generate\n",
            "INFO:tensorflow:Checkpoint used: /content/log/run0/model.ckpt-1931\n",
            "INFO:tensorflow:Restoring parameters from /content/log/run0/model.ckpt-1931\n",
            "WARNING:tensorflow:*******************************************************\n",
            "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
            "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
            "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
            "WARNING:tensorflow:now on by default.\n",
            "WARNING:tensorflow:*******************************************************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tlhkMihuulM_",
        "colab_type": "code",
        "outputId": "ae02d10a-f704-49af-ecd8-d01f85ef05b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1496
        }
      },
      "cell_type": "code",
      "source": [
        "!python /usr/local/lib/python2.7/dist-packages/magenta/models/performance_rnn/performance_rnn_generate.py \\\n",
        "--bundle_file=/content/log/run0bundle.mag \\\n",
        "--output_dir=/content/log/ \\\n",
        "--config=performance_with_dynamics \\\n",
        "--num_outputs=1 \\\n",
        "--num_steps=1000 \n",
        "# --primer_melody=\"[53, 57, 60, 57, 60, 57, 53, 57, 60, 57, 60, 57]\"\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/scipy/signal/_max_len_seq.py:8: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from ._max_len_seq_inner import _max_len_seq_inner\n",
            "/usr/local/lib/python2.7/dist-packages/scipy/signal/_upfirdn.py:36: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from ._upfirdn_apply import _output_len, _apply\n",
            "/usr/local/lib/python2.7/dist-packages/scipy/signal/spectral.py:10: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from ._spectral import _lombscargle\n",
            "/usr/local/lib/python2.7/dist-packages/scipy/signal/_peak_finding.py:13: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from ._peak_finding_utils import (_argmaxima1d, _select_by_peak_distance,\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/base.py:35: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from ..utils.seq_dataset import ArrayDataset, CSRDataset\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/least_angle.py:23: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from ..utils import arrayfuncs, as_float_array, check_X_y, deprecated\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/utils/random.py:10: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from ._random import sample_without_replacement\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/coordinate_descent.py:30: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from . import cd_fast\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/__init__.py:22: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from .sgd_fast import Hinge, Log, ModifiedHuber, SquaredLoss, Huber\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/__init__.py:22: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from .sgd_fast import Hinge, Log, ModifiedHuber, SquaredLoss, Huber\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/sag.py:12: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from .sag_fast import sag\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/svm/base.py:8: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from . import libsvm, liblinear\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/svm/base.py:8: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from . import libsvm, liblinear\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/svm/base.py:9: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from . import libsvm_sparse\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/neighbors/__init__.py:6: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from .ball_tree import BallTree\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/neighbors/__init__.py:6: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from .ball_tree import BallTree\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/neighbors/__init__.py:6: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from .ball_tree import BallTree\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/neighbors/__init__.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from .kd_tree import KDTree\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/decomposition/online_lda.py:28: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from ._online_lda import (mean_change, _dirichlet_expectation_1d,\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/utils/graph.py:16: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from .graph_shortest_path import graph_shortest_path  # noqa\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/isotonic.py:11: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from ._isotonic import _inplace_contiguous_isotonic_regression, _make_unique\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/manifold/t_sne.py:26: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from . import _utils\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/manifold/t_sne.py:27: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from . import _barnes_hut_tsne\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/manifold/t_sne.py:27: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from . import _barnes_hut_tsne\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/tree/tree.py:40: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from ._criterion import Criterion\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/tree/tree.py:40: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from ._criterion import Criterion\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/tree/tree.py:40: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from ._criterion import Criterion\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/tree/tree.py:40: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from ._criterion import Criterion\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/cluster/k_means_.py:37: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from . import _k_means\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/cluster/k_means_.py:38: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from ._k_means_elkan import k_means_elkan\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/cluster/hierarchical.py:23: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from . import _hierarchical\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/cluster/hierarchical.py:23: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from . import _hierarchical\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/cluster/dbscan_.py:20: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from ._dbscan_inner import dbscan_inner\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/feature_extraction/hashing.py:14: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
            "  from ._hashing import transform as _hashing_transform\n",
            "WARNING:tensorflow:No priming sequence specified. Defaulting to empty sequence.\n",
            "2019-01-07 13:12:00.083218: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-01-07 13:12:00.083725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 10.97GiB\n",
            "2019-01-07 13:12:00.083795: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2019-01-07 13:12:00.514483: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-01-07 13:12:00.514572: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2019-01-07 13:12:00.514615: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2019-01-07 13:12:00.514916: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-01-07 13:12:00.514990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10625 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpLOk0W8/model.ckpt\n",
            "INFO:tensorflow:Need to generate 899 more steps for this sequence, will try asking for 540 RNN steps\n",
            "INFO:tensorflow:Beam search yields sequence with log-likelihood: -1265.212036 \n",
            "INFO:tensorflow:Wrote 1 MIDI files to /content/log/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iEwbgQ_YM3YI",
        "colab_type": "code",
        "outputId": "2695114e-fa7f-438b-d19e-0b5e25777e78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "cell_type": "code",
      "source": [
        "!ls -l /content/log/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 16256\n",
            "-rw-r--r-- 1 root root      236 Jan  7 13:14 2019-01-07_131159_1.mid\n",
            "drwxr-xr-x 2 root root     4096 Jan  7 13:10 run0\n",
            "-rw-r--r-- 1 root root 16635559 Jan  7 13:11 run0bundle.mag\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-vy9zhTEBQU2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp /content/log/2019-01-07_131159_1.mid /content"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qgxmrc40ClHn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "files.download('/content/log/2019-01-07_131159_1.mid')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WZDjeoU5a5ov",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## VAE"
      ]
    },
    {
      "metadata": {
        "id": "LI-bNEpua8sn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.python.util import nest as tf_nest\n",
        "\n",
        "config.latent_size\n",
        "config.encoders[]\n",
        "config.decoders[]\n",
        "\n",
        "def build_vae(config, mode):\n",
        "  \n",
        "  def build_graph():\n",
        "\n",
        "    encoder_decoder = config['encoder_decoder']\n",
        "    input_size = encoder_decoder.input_size\n",
        "    num_classes = encoder_decoder.num_classes\n",
        "    default_event_label = encoder_decoder.default_event_label\n",
        "\n",
        "    batch_size = 512\n",
        "    label_shape = []\n",
        "    learning_rate = config['learning_rate']\n",
        "    inputs, labels, lengths = None, None, None\n",
        "    if mode == 'train' or mode == 'eval':\n",
        "      inputs, labels, lengths = mg.common.get_padded_batch(\n",
        "                ['/content/sequences/training_performances.tfrecord'], batch_size, input_size,\n",
        "                label_shape=label_shape, shuffle=mode == 'train')\n",
        "    else:\n",
        "      inputs = tf.placeholder(tf.float32, [batch_size, None,\n",
        "                                           input_size])\n",
        "    config['dropouts'] = [1.0 if mode == 'generate' else dropout for dropout in config['dropouts']]\n",
        "    encoder_cell = get_deep_lstm(config['encoder_layers'], config['dropout'])          \n",
        "    decoder_cell = get_deep_lstm(config['decoder_layers'], config['dropout'])\n",
        "           \n",
        "    initial_state = cell.zero_state(batch_size, tf.float32)\n",
        "    outputs, final_state = tf.nn.dynamic_rnn(\n",
        "        cell, inputs, sequence_length=lengths, initial_state=initial_state,\n",
        "        swap_memory=True)\n",
        "    \n",
        "    # Copmute our latent space\n",
        "    mu = tf.layers.dense(outputs, config[\"z_size\"], \n",
        "                         kernel_initializer=tf.random_normal_initializer(stddev=0.001))\n",
        "    sigma = tf.layers.dense(outputs, config[\"z_size\"], \n",
        "                            activation=tf.nn.softplus,\n",
        "                            kernel_initializer=tf.random_normal_initializer(stddev=0.001))\n",
        "    z = tfp.distributions.MultivariateNormalDiag(loc=mu, scale_diag=sigma)\n",
        "    \n",
        "      \n",
        "    outputs_flat = mg.common.flatten_maybe_padded_sequencest(\n",
        "            outputs, lengths)\n",
        "    \n",
        "    num_logits = num_classes\n",
        "    logits_flat = tf.contrib.layers.linear(outputs_flat, num_logits)\n",
        "                                           \n",
        "    if mode == 'train' or mode == 'eval':\n",
        "      labels_flat = mg.common.flatten_maybe_padded_sequences(\n",
        "              labels, lengths)\n",
        "      \n",
        "      softmax_cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "            labels=labels_flat, logits=logits_flat)\n",
        "      predictions_flat = tf.argmax(logits_flat, axis=1)\n",
        "      correct_predictions = tf.to_float(\n",
        "          tf.equal(labels_flat, predictions_flat))\n",
        "      event_positions = tf.to_float(tf.not_equal(labels_flat, default_event_label))\n",
        "      no_event_positions = tf.to_float(tf.equal(labels_flat, default_event_label))\n",
        "\n",
        "      loss = tf.reduce_mean(softmax_cross_entropy)\n",
        "      optimizer = config['optimizer'](learning_rate=config['learning_rate'])\n",
        "      train_op = tf.contrib.slim.learning.create_train_op(loss, optimizer)\n",
        "      \n",
        "      tf.summary.scalar('loss', loss)\n",
        "      tf.add_to_collection('loss', loss)\n",
        "      tf.add_to_collection('train_op', train_op)\n",
        "      tf.add_to_collection('optimizer', optimizer)\n",
        "    elif mode == 'generate':\n",
        "      temperature = tf.placeholder(tf.float32, [])\n",
        "      softmax_flat = tf.nn.softmax(\n",
        "            tf.div(logits_flat, tf.fill([num_classes], temperature)))\n",
        "      softmax = tf.reshape(\n",
        "            softmax_flat, [batch_size, -1, num_classes])\n",
        "    \n",
        "      tf.add_to_collection('inputs', inputs)\n",
        "      tf.add_to_collection('temperature', temperature)\n",
        "      tf.add_to_collection('softmax', softmax)\n",
        "\n",
        "      for state in tf_nest.flatten(initial_state):\n",
        "        tf.add_to_collection('initial_state', state)\n",
        "      for state in tf_nest.flatten(final_state):\n",
        "        tf.add_to_collection('final_state', state)\n",
        "  return build_graph"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dtKtB8cqVMwY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Old stuff"
      ]
    },
    {
      "metadata": {
        "id": "8X5H2VtdvUbr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import LSTM, Dense, Input, Lambda, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "def autoencoder(batch_size, features, label_dim, latent_dim=64):\n",
        "  input_layer = Input(shape=(features.shape[1],1,))\n",
        "\n",
        "  #Encoder layers\n",
        "  hidden1 = LSTM(512)(input_layer)\n",
        "  \n",
        "  #Mean and std\n",
        "  z_mean = Dense(latent_dim)(hidden1)\n",
        "  z_log_sigma = Dense(latent_dim)(hidden1)\n",
        "  \n",
        "  #Sampled latent layer\n",
        "  z = Lambda(sample)([z_mean, z_log_sigma])\n",
        "  \n",
        "#   hidden2 = LSTM(512, return_sequences=True)(z)\n",
        "  \n",
        "  #Decoder layers\n",
        "#   hidden2 = RepeatVector(features.shape[1])(z)\n",
        "#   hidden3 = LSTM(512, activation='sigmoid', return_sequences=True)(hidden2)\n",
        "  \n",
        "  #Output layers\n",
        "#   output_layer = Dense(label_dim, activation='softmax')(hidden3)\n",
        "  \n",
        "  return Model(input_layer, z)\n",
        "def sample(args):\n",
        "  z_mean, z_log_var = args\n",
        "  batch = K.shape(z_mean)[0]\n",
        "  dim = K.int_shape(z_mean)[1]\n",
        "  \n",
        "  # by default, random_normal has mean=0 and std=1.0\n",
        "  epsilon = K.random_normal(shape=(batch, dim))\n",
        "  return z_mean + K.exp(0.5 * z_log_var) * epsilon"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3_ukQLEsMrPu",
        "colab_type": "code",
        "outputId": "7f1d7a04-1a78-45de-ef6a-18121953c70f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        }
      },
      "cell_type": "code",
      "source": [
        "def get_model(input_tensor):\n",
        "  input_layer = Input(tensor=input_tensor)\n",
        "  x = LSTM(512, return_sequences=True)(input_layer)\n",
        "  x = Dropout(0.3)(x)\n",
        "  x = LSTM(512)(x)\n",
        "  x = Dense(512)(x)\n",
        "  x = Dropout(0.3)(x)\n",
        "  x = Dense(388, activation='softmax')(x)\n",
        "  return Model(input_layer, x)\n",
        "model = get_model(inputs)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-bee2c61abf2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m388\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'inputs' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "2pwQMcXel4WJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Data processing"
      ]
    },
    {
      "metadata": {
        "id": "1Ypdnb98Ktg1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "def get_midi(notes, directory):\n",
        "  for file in glob.glob(directory  + \"/*.mid\"):\n",
        "    midi = converter.parse(file)\n",
        "    notes_to_parse = None\n",
        "\n",
        "    parts = instrument.partitionByInstrument(midi)\n",
        "    if parts:\n",
        "      notes_to_parse = parts.parts[0].recurse()\n",
        "    else:\n",
        "      notes_to_parse = midi.flat.notes\n",
        "\n",
        "    for element in notes_to_parse:\n",
        "      if isinstance(element, note.Note):\n",
        "        notes.append(str(element.pitch))\n",
        "      elif isinstance(element, chord.Chord):\n",
        "        notes.append('.'.join(str(n) for n in element.normalOrder))\n",
        "\n",
        "  return notes\n",
        "\n",
        "def get_input_output(notes, note_to_int, sequence_length):\n",
        "  \n",
        "  network_input, network_output = [], []\n",
        "  for i in range(0, len(notes) - sequence_length, 1):\n",
        "    sequence_in = notes[i:i + sequence_length]\n",
        "    sequence_out = notes[i + sequence_length]\n",
        "    network_input.append([note_to_int[char] for char in sequence_in])\n",
        "    network_output.append(note_to_int[sequence_out])\n",
        "  return network_input, network_output\n",
        "\n",
        "def normalize_data(network_input, network_output, sequence_length, n_vocab):\n",
        "  n_patterns = len(network_input)\n",
        "  normalized_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
        "  normalized_input = normalized_input / float(n_vocab)\n",
        "  normalized_output = keras.utils.to_categorical(network_output)\n",
        "  \n",
        "  return normalized_input, normalized_output\n",
        "\n",
        "def get_data(notes, sequence_length=75):\n",
        "  pitchnames = sorted(set(item for item in notes))\n",
        "  note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
        "  n_vocab = len(set(notes))\n",
        "  \n",
        "  network_input, network_output = get_input_output(notes, note_to_int, sequence_length)\n",
        "  normalized_input, normalized_output = normalize_data(network_input, \n",
        "                                                       network_output, \n",
        "                                                       sequence_length, \n",
        "                                                       n_vocab)\n",
        "  \n",
        "  return normalized_input, normalized_output, n_vocab, note_to_int, pitchnames"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fQNKDDNELxs5",
        "colab_type": "code",
        "outputId": "d645eaa5-bf20-4300-b0c1-829d81153036",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1702
        }
      },
      "cell_type": "code",
      "source": [
        "# Grab some data\n",
        "!git clone https://github.com/Skuldur/Classical-Piano-Composer\n",
        "# !git clone https://github.com/brannondorsey/midi-rnn\n",
        "# !wget \"www.kuhmann.com/Disklavier/Classical-II%20(215)%20MID.zip\"\n",
        "# !wget \"www.kuhmann.com/Disklavier/Classical-I%20(001-215)%20MID.zip\"\n",
        "\n",
        "# Organise MIDI files for parsing\n",
        "!mkdir data\n",
        "# !unzip 'Classical-I (001-215) MID.zip' -q -d /content/data/\n",
        "# !unzip 'Classical-II (215) MID.zip' -d /content/data/\n",
        "!mv Classical-Piano-Composer/midi_songs/*.mid /content/data/\n",
        "!ls data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Classical-Piano-Composer'...\n",
            "remote: Enumerating objects: 150, done.\u001b[K\n",
            "remote: Total 150 (delta 0), reused 0 (delta 0), pack-reused 150\u001b[K\n",
            "Receiving objects: 100% (150/150), 117.92 MiB | 10.86 MiB/s, done.\n",
            "Resolving deltas: 100% (18/18), done.\n",
            " 0fithos.mid\n",
            " 8.mid\n",
            " ahead_on_our_way_piano.mid\n",
            " AT.mid\n",
            " balamb.mid\n",
            " bcm.mid\n",
            " BlueStone_LastDungeon.mid\n",
            " braska.mid\n",
            " caitsith.mid\n",
            " Cids.mid\n",
            " cosmo.mid\n",
            " costadsol.mid\n",
            " dayafter.mid\n",
            " decisive.mid\n",
            " dontbeafraid.mid\n",
            " DOS.mid\n",
            " electric_de_chocobo.mid\n",
            " Eternal_Harvest.mid\n",
            " EyesOnMePiano.mid\n",
            " ff11_awakening_piano.mid\n",
            " ff1battp.mid\n",
            "'FF3_Battle_(Piano).mid'\n",
            "'FF3_Third_Phase_Final_(Piano).mid'\n",
            " ff4-airship.mid\n",
            " Ff4-BattleLust.mid\n",
            " ff4-fight1.mid\n",
            " FF4.mid\n",
            " ff4pclov.mid\n",
            " ff4_piano_collections-main_theme.mid\n",
            " ff4-town.mid\n",
            " FF6epitaph_piano.mid\n",
            " ff6shap.mid\n",
            " Ff7-Cinco.mid\n",
            " Ff7-Jenova_Absolute.mid\n",
            " ff7-mainmidi.mid\n",
            " Ff7-One_Winged.mid\n",
            " ff7themep.mid\n",
            " ff8-lfp.mid\n",
            " FF8_Shuffle_or_boogie_pc.mid\n",
            " FFIII_Edgar_And_Sabin_Piano.mid\n",
            " FFIX_Piano.mid\n",
            " FFIXQuMarshP.mid\n",
            " FFVII_BATTLE.mid\n",
            "'FFX_-_Ending_Theme_(Piano_Version)_-_by_Angel_FF.mid'\n",
            "'Fiend_Battle_(Piano).mid'\n",
            "'Fierce_Battle_(Piano).mid'\n",
            " figaro.mid\n",
            " Finalfantasy5gilgameshp.mid\n",
            " Finalfantasy6fanfarecomplete.mid\n",
            " Final_Fantasy_7_-_Judgement_Day_Piano.mid\n",
            " Final_Fantasy_Matouyas_Cave_Piano.mid\n",
            " fortresscondor.mid\n",
            " Fyw_piano.mid\n",
            " gerudo.mid\n",
            " goldsaucer.mid\n",
            " Gold_Silver_Rival_Battle.mid\n",
            " great_war.mid\n",
            " HighwindTakestotheSkies.mid\n",
            " In_Zanarkand.mid\n",
            " JENOVA.mid\n",
            " Kingdom_Hearts_Dearly_Beloved.mid\n",
            " Kingdom_Hearts_Traverse_Town.mid\n",
            " Life_Stream.mid\n",
            " lurk_in_dark.mid\n",
            " mining.mid\n",
            " Oppressed.mid\n",
            " OTD5YA.mid\n",
            " path_of_repentance.mid\n",
            " pkelite4.mid\n",
            " Rachel_Piano_tempofix.mid\n",
            " redwings.mid\n",
            " relmstheme-piano.mid\n",
            " roseofmay-piano.mid\n",
            " rufus.mid\n",
            " Rydia_pc.mid\n",
            " sandy.mid\n",
            " sera_.mid\n",
            " sobf.mid\n",
            " Still_Alive-1.mid\n",
            "'Suteki_Da_Ne_(Piano_Version).mid'\n",
            " thenightmarebegins.mid\n",
            " thoughts.mid\n",
            " tifap.mid\n",
            " tpirtsd-piano.mid\n",
            " traitor.mid\n",
            " ultimafro.mid\n",
            " ultros.mid\n",
            " VincentPiano.mid\n",
            " ViviinAlexandria.mid\n",
            " waltz_de_choco.mid\n",
            " z_aeristhemepiano.mid\n",
            " Zelda_Overworld.mid\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bAwyB7qYl8O2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Training\n"
      ]
    },
    {
      "metadata": {
        "id": "erSaeJs6K1YW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "notes = get_midi([], \"/content/data\")\n",
        "network_input, network_output, n_vocab, note_to_int, pitchnames = get_data(notes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zL6BlhSTmfqV",
        "colab_type": "code",
        "outputId": "cc448218-f7a2-4680-ce3a-0f750641576e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "n_vocab"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "358"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "metadata": {
        "id": "eLA6xPNGLiy0",
        "colab_type": "code",
        "outputId": "a68a8922-5506-4f1e-fc9f-5b728ca65e0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "cell_type": "code",
      "source": [
        "model = autoencoder(network_input, n_vocab)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_27 (InputLayer)           (None, 75, 1)        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_42 (LSTM)                  (None, 512)          1052672     input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_61 (Dense)                (None, 64)           32832       lstm_42[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_62 (Dense)                (None, 64)           32832       lstm_42[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_24 (Lambda)              (None, 64)           0           dense_61[0][0]                   \n",
            "                                                                 dense_62[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 1,118,336\n",
            "Trainable params: 1,118,336\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dGKm_N2PdzBa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8-sRJ4aov7yj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Noodling"
      ]
    },
    {
      "metadata": {
        "id": "ZFgQOGCOv8YN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from magenta.music import midi_io\n",
        "def convert_midi(root_dir, sub_dir, full_file_path):\n",
        "  \"\"\"Converts a midi file to a sequence proto.\n",
        " \n",
        "  Args:\n",
        "    root_dir: A string specifying the root directory for the files being\n",
        "        converted.\n",
        "    sub_dir: The directory being converted currently.\n",
        "    full_file_path: the full path to the file to convert.\n",
        "\n",
        "  Returns:\n",
        "    Either a NoteSequence proto or None if the file could not be converted.\n",
        "  \"\"\"\n",
        "  try:\n",
        "    sequence = midi_io.midi_to_sequence_proto(\n",
        "        tf.gfile.FastGFile(full_file_path, 'rb').read())\n",
        "  except midi_io.MIDIConversionError as e:\n",
        "    tf.logging.warning(\n",
        "        'Could not parse MIDI file %s. It will be skipped. Error was: %s',\n",
        "        full_file_path, e)\n",
        "    return None\n",
        "  sequence.collection_name = os.path.basename(root_dir)\n",
        "  sequence.filename = os.path.join(sub_dir, os.path.basename(full_file_path))\n",
        "  sequence.id = note_sequence_io.generate_note_sequence_id(\n",
        "      sequence.filename, sequence.collection_name, 'midi')\n",
        "  tf.logging.info('Converted MIDI file %s.', full_file_path)\n",
        "  return sequence\n",
        "\n",
        "\n",
        "\n",
        "def convert_files(root_dir, sub_dir, writer, recursive=False):\n",
        "  \"\"\"Converts files.\n",
        "\n",
        "  Args:\n",
        "    root_dir: A string specifying a root directory.\n",
        "    sub_dir: A string specifying a path to a directory under `root_dir` in which\n",
        "        to convert contents.\n",
        "    writer: A TFRecord writer\n",
        "    recursive: A boolean specifying whether or not recursively convert files\n",
        "        contained in subdirectories of the specified directory.\n",
        "\n",
        "  Returns:\n",
        "    A map from the resulting Futures to the file paths being converted.\n",
        "  \"\"\"\n",
        "  dir_to_convert = os.path.join(root_dir, sub_dir)\n",
        "  tf.logging.info(\"Converting files in '%s'.\", dir_to_convert)\n",
        "  files_in_dir = tf.gfile.ListDirectory(os.path.join(dir_to_convert))\n",
        "  recurse_sub_dirs = []\n",
        "  written_count = 0\n",
        "  for file_in_dir in files_in_dir:\n",
        "    tf.logging.log_every_n(tf.logging.INFO, '%d files converted.',\n",
        "                           1000, written_count)\n",
        "    full_file_path = os.path.join(dir_to_convert, file_in_dir)\n",
        "    if (full_file_path.lower().endswith('.mid') or\n",
        "        full_file_path.lower().endswith('.midi')):\n",
        "      try:\n",
        "        sequence = convert_midi(root_dir, sub_dir, full_file_path)\n",
        "      except Exception as exc:  # pylint: disable=broad-except\n",
        "        tf.logging.fatal('%r generated an exception: %s', full_file_path, exc)\n",
        "        continue\n",
        "      if sequence:\n",
        "        writer.write(sequence)\n",
        "    else:\n",
        "      if recursive and tf.gfile.IsDirectory(full_file_path):\n",
        "        recurse_sub_dirs.append(os.path.join(sub_dir, file_in_dir))\n",
        "      else:\n",
        "        tf.logging.warning(\n",
        "            'Unable to find a converter for file %s', full_file_path)\n",
        "\n",
        "  for recurse_sub_dir in recurse_sub_dirs:\n",
        "    convert_files(root_dir, recurse_sub_dir, writer, recursive)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "saKjHkn0wFbg",
        "colab_type": "code",
        "outputId": "b8cae0b6-0b93-408c-f1cd-72c899e3a786",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "cell_type": "code",
      "source": [
        "writer = tf.TFRecordWriter()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-320b3289b3cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFRecordWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'TFRecordWriter'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "-Ete9U2owK0w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}